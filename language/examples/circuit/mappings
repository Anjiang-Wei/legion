Task * GPU,CPU; # for any task, run on GPU if supported

Region * * GPU FBMEM; # for any task, any region, if mapped onto GPU, use FBMEM as default
Region * * CPU SYSMEM; # for this benchmark, it's mapped onto CPU, so it will use SYSMEM as default

# for $task, $region, if mapped onto $proc_type, specify $mem_type to use
# https://github.com/Anjiang-Wei/legion/blob/circuit_example/language/examples/circuit_bishop.rg#L24-L62 specifies GPU
# but since this benchmark is actually mapped onto CPU, I use CPU instead (using wildcard * is also fine)
# for region names, we need to use the region names that are passed in (instead of what is defined in task)
Region calculate_new_currents pn_shared CPU ZCMEM;
Region calculate_new_currents pn_ghost CPU ZCMEM;
Region distribute_charge pn_shared * ZCMEM;
Region distribute_charge pn_ghost * ZCMEM;
Region update_voltages pn_equal * ZCMEM;

# for $task, $region, $mem_type, specify $list_of_layout_constraints
Layout * * * SOA C_order; # Other choices: AOS F_order Exact Align==128 Compact

mcpu_init = Machine(CPU); # nodes * processors
mcpu = mcpu_init.merge(0, 1); # 1-dim processors

mgpu_init = Machine(GPU); # nodes * processors
mgpu = mgpu_init.merge(0, 1); # 1-dim processors

# m = mgpu.volume > 0 ? mgpu : mcpu; # we can use tenary operator
m = mcpu; # in this circuit example, all tasks are mapped to CPU though we have GPUs available

def cyclic1d(Task task) {
    # task.ispace is a n-dim tuple (in this case n=1) indicating launch domain, not used here
    return m[task.ipoint[0] % m.size[0]]; # return one point in a machine model (or generally, can be a subset of points on the same node)
}

# specify $task_name(s) and sharding+slicing function
IndexTaskMap calculate_new_currents,distribute_charge,update_voltages cyclic1d;
